{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 151A Group Project: Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of our imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform, poisson\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to suppress warnings when running code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must get our processed data to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv('processed_input.csv')\n",
    "output_df = pd.read_csv('processed_output.csv')\n",
    "display(input_df)\n",
    "display(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_df,output_df, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training data shapes: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Validation data shapes: {X_val.shape}, {y_val.shape}')\n",
    "print(f'Test data shape: {X_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_error_list = []\n",
    "training_error_list = []\n",
    "testing_error_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model=DecisionTreeRegressor()\n",
    "decision_tree_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our starting off point for error\n",
    "yhat_train = decision_tree_model.predict(X_train)\n",
    "train_error = mean_squared_error(y_train,yhat_train)\n",
    "training_error_list.append(np.log(train_error))\n",
    "print('Training Error:',train_error)\n",
    "\n",
    "yhat_test = decision_tree_model.predict(X_test)\n",
    "test_error = mean_squared_error(y_test,yhat_test)\n",
    "testing_error_list.append(np.log(test_error))\n",
    "print('Testing Error:',test_error)\n",
    "\n",
    "yhat_val = decision_tree_model.predict(X_val)\n",
    "val_error = mean_squared_error(y_val,yhat_val)\n",
    "validation_error_list.append(np.log(val_error))\n",
    "print('Validation Error:',val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters={\"splitter\":[\"best\",\"random\"],\n",
    "#             \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "#            \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "#            \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "#            \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "#            \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n",
    "# parameters = {\n",
    "#     'splitter':[\"best\",\"random\"],\n",
    "#     'max_depth': [3,5,7],\n",
    "#     'min_samples_split': [3,5,7,9],\n",
    "#     'min_samples_leaf': [3,5,7,9],\n",
    "#     \"max_leaf_nodes\":[10,20,30,40]\n",
    "# }\n",
    "parameters = {'criterion':['friedman_mse','squared_error'],\n",
    "              'max_depth':np.arange(1,15).tolist()[0::2],\n",
    "              'min_samples_split':np.arange(2,11).tolist()[0::2],\n",
    "              'max_leaf_nodes':np.arange(3,20).tolist()[0::2]}\n",
    "tuning_model=GridSearchCV(decision_tree_model,parameters,scoring='neg_mean_squared_error',cv=10,verbose=0, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_decision_tree_model = DecisionTreeRegressor(max_depth=7,max_leaf_nodes=19, min_samples_split=2, criterion='friedman_mse')\n",
    "tuned_decision_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show our starting off point for error\n",
    "yhat_train = tuned_decision_tree_model.predict(X_train)\n",
    "train_error = mean_squared_error(y_train,yhat_train)\n",
    "training_error_list.append(np.log(train_error))\n",
    "print('Training Error:',train_error)\n",
    "\n",
    "yhat_test = tuned_decision_tree_model.predict(X_test)\n",
    "test_error = mean_squared_error(y_test,yhat_test)\n",
    "testing_error_list.append(np.log(test_error))\n",
    "print('Testing Error:',test_error)\n",
    "\n",
    "yhat_val = tuned_decision_tree_model.predict(X_val)\n",
    "val_error = mean_squared_error(y_val,yhat_val)\n",
    "validation_error_list.append(np.log(val_error))\n",
    "print('Validation Error:',val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Number of trees in the forest\n",
    "    'max_depth': [10, 25],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 3]  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_grid_search_model = RandomForestRegressor(max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "tuned_grid_search_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print train, test, and validation errors\n",
    "yhat_train = tuned_grid_search_model.predict(X_train)\n",
    "train_error = mean_squared_error(y_train,yhat_train)\n",
    "print('Training Error:',train_error)\n",
    "\n",
    "yhat_test = tuned_grid_search_model.predict(X_test)\n",
    "test_error = mean_squared_error(y_test,yhat_test)\n",
    "print('Testing Error:',test_error)\n",
    "\n",
    "yhat_val = tuned_grid_search_model.predict(X_val)\n",
    "val_error = mean_squared_error(y_val,yhat_val)\n",
    "print('Validation Error:',val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try out a few Gradient Boosting libraries to see if we can improve upon our current error. We'll start with the most popular one: XGBoost. Gradient boosting is an ensemble method involving multiple shallow decision trees that correct each others' mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting models\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [5,7,9],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.7, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.9, 0.95],\n",
    "    'gamma': [0, 0.1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel = xgb.XGBRegressor(learning_rate= 0.1, max_depth= 7, n_estimators= 200, \n",
    "                         colsample_bytree= 0.7, subsample = 0.9, gamma=0)\n",
    "xgbmodel.fit(X_train, y_train)\n",
    "\n",
    "xgbmodel.save_model('part_2_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = xgbmodel.predict(X_train)\n",
    "train_error = mean_squared_error(y_train,yhat_train)\n",
    "print('Training Error:',train_error)\n",
    "\n",
    "yhat_test = xgbmodel.predict(X_test)\n",
    "test_error = mean_squared_error(y_test,yhat_test)\n",
    "print('Testing Error:',test_error)\n",
    "\n",
    "yhat_val = xgbmodel.predict(X_val)\n",
    "val_error = mean_squared_error(y_val,yhat_val)\n",
    "print('Validation Error:',val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying scikitlearn's built in gradient booster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# View Results\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbmodel = GradientBoostingRegressor(learning_rate= 0.05, max_depth= 5, n_estimators= 300)\n",
    "gbmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = gbmodel.predict(X_train)\n",
    "train_error = mean_squared_error(y_train,yhat_train)\n",
    "print('Training Error:',train_error)\n",
    "\n",
    "yhat_test = gbmodel.predict(X_test)\n",
    "test_error = mean_squared_error(y_test,yhat_test)\n",
    "print('Testing Error:',test_error)\n",
    "\n",
    "yhat_val = gbmodel.predict(X_val)\n",
    "val_error = mean_squared_error(y_val,yhat_val)\n",
    "print('Validation Error:',val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
